# -*- coding: utf-8 -*-
"""wesad.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JfWYmKxM7v6xA-XfnqUeAxRNXh7-ATwj
"""

pip install pandas scikit-learn tensorflow xgboost

# Step 1: Drop rows with missing or non-numeric labels
df = df[pd.to_numeric(df["label"], errors="coerce").notnull()]
df["label"] = df["label"].astype(int)

# Step 2: Ensure labels are within expected range (1 to 3)
df = df[df["label"].isin([1, 2, 3])]

# Step 3: Now shift labels from 1‚Äì3 to 0‚Äì2
y = df["label"] - 1

# Step 4: Check that all labels are valid
print("Label values after cleaning:", y.unique())

# Step 5: One-hot encode
y_cat = to_categorical(y, num_classes=3)

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dense
from tensorflow.keras.utils import to_categorical
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix

# Load Data
df = pd.read_csv("combined1.csv")
X = df.drop(columns=["Unnamed: 0", "timestamp", "label", "subject"])
y = df["label"] - 1  # Labels 1‚Äì3 ‚Üí 0‚Äì2

# Standardize Features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Reshape for BiLSTM: (samples, timesteps, features)
# Here we treat the 24 features as a "sequence" of 24 steps with 1 feature each
X_seq = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)

# One-hot encode labels
y_cat = to_categorical(y, num_classes=3)

# Train-test split
X_train_seq, X_test_seq, y_train_cat, y_test_cat, y_train, y_test = train_test_split(
    X_seq, y_cat, y, test_size=0.2, random_state=42, stratify=y
)

# --- BiLSTM Model for Feature Extraction ---
input_layer = Input(shape=(X_seq.shape[1], 1))
x = Bidirectional(LSTM(64, return_sequences=True))(input_layer)
x = LSTM(32)(x)
dense = Dense(32, activation='relu')(x)  # 32-dimensional output

feature_extractor = Model(inputs=input_layer, outputs=dense)
features_train = feature_extractor.predict(X_train_seq)
features_test = feature_extractor.predict(X_test_seq)

# --- XGBoost Classifier ---
xgb_model = XGBClassifier(
    objective='multi:softprob',
    num_class=3,
    n_estimators=100,
    eval_metric='mlogloss',
    use_label_encoder=False
)
xgb_model.fit(features_train, y_train)

# Predict and Evaluate
y_pred = xgb_model.predict(features_test)

print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler
from sklearn.cross_decomposition import CCA
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# --- Step 1: Load Features ---
df = pd.read_csv("wesad_features_30s.csv")

# Encode labels
le = LabelEncoder()
df["label"] = le.fit_transform(df["label"])
y = df["label"].values

# --- Step 2: Define Modalities ---
modalities = {
    "GSR": [col for col in df.columns if "acc" in col.lower() or "gsr" in col.lower()],
    "BVP": [col for col in df.columns if "bvp" in col.lower()],
    "TEMP": [col for col in df.columns if "temp" in col.lower()]
}

# Drop non-feature columns
df_clean = df.drop(columns=["label", "subject", "timestamp"], errors='ignore')

# --- Step 3: Standardize Modalities ---
X_modalities = {}
scalers = {}

for mod, cols in modalities.items():
    X_mod = df[cols].copy()
    if X_mod.shape[1] > 0:  # Skip empty modality
        scaler = StandardScaler()
        X_modalities[mod] = scaler.fit_transform(X_mod)
        scalers[mod] = scaler

# --- Step 4: One-Hot Encode Labels for Supervised CCA ---
y_onehot = OneHotEncoder(sparse_output=False).fit_transform(y.reshape(-1, 1))

# --- Step 5: Apply CCA Per Modality ---
cca_components = 10
X_projected = []
cca_models = {}

for mod, X in X_modalities.items():
    cca = CCA(n_components=min(cca_components, X.shape[1], y_onehot.shape[1]))
    X_c, _ = cca.fit_transform(X, y_onehot)
    X_projected.append(X_c)
    cca_models[mod] = cca

# --- Step 6: Concatenate Projected Modalities ---
X_final = np.concatenate(X_projected, axis=1)

# --- Step 7: Train/Test Split ---
X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)

# --- Step 8: Train Classifier ---
clf = RandomForestClassifier(n_estimators=200, random_state=42)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

# --- Step 9: Evaluate ---
print("üìä Classification Report:\n")
print(classification_report(y_test, y_pred, target_names=[str(c) for c in le.classes_]))

import pandas as pd
import numpy as np
from scipy.fft import fft
from scipy.stats import linregress

# --- Step 1: Load Data ---
df = pd.read_csv("combined1.csv")
df = df.drop(columns=["Unnamed: 0"], errors='ignore')

# --- Step 2: Define windowing parameters ---
window_size = 30  # seconds
sampling_rate = 1  # 1 Hz assumed (1 row per second); change if needed
samples_per_window = window_size * sampling_rate

# --- Step 3: Feature Extraction Functions ---
def extract_statistical_features(segment):
    features = {}
    for col in segment.columns:
        x = segment[col].values
        slope = linregress(range(len(x)), x).slope
        features[f"{col}_mean"] = np.mean(x)
        features[f"{col}_std"] = np.std(x)
        features[f"{col}_slope"] = slope
    return features

def extract_fft_features(segment):
    features = {}
    for col in segment.columns:
        x = segment[col].values
        fft_vals = np.abs(fft(x))
        top_freqs = np.sort(fft_vals[1:])[-3:]  # skip DC
        for i, val in enumerate(top_freqs):
            features[f"{col}_fft_{i+1}"] = val
    return features

# --- Step 4: Apply windowing and extract features ---
feature_rows = []
labels = []
subjects = []

sensor_columns = [col for col in df.columns if col not in ["timestamp", "label", "subject"]]

for subject in df["subject"].unique():
    subject_df = df[df["subject"] == subject].reset_index(drop=True)

    for i in range(0, len(subject_df) - samples_per_window + 1, samples_per_window):
        window = subject_df.iloc[i:i+samples_per_window]
        if window["label"].nunique() == 1:  # Ensure label is consistent in window
            label = window["label"].iloc[0]
            stat_features = extract_statistical_features(window[sensor_columns])
            fft_features = extract_fft_features(window[sensor_columns])
            feature_row = {**stat_features, **fft_features}
            feature_rows.append(feature_row)
            labels.append(label)
            subjects.append(subject)

# --- Step 5: Final Feature Matrix ---
features_df = pd.DataFrame(feature_rows)
features_df["label"] = labels
features_df["subject"] = subjects

# Save to CSV (optional)
features_df.to_csv("wesad_features_30s_1.csv", index=False)
print("‚úÖ Features extracted. Final shape:", features_df.shape)

!pip install mvlearn

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dense
from tensorflow.keras.utils import to_categorical
from xgboost import XGBClassifier
from mvlearn.embed import GCCA

# --- Step 1: Load Extracted Features ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")

# --- Step 2: Prepare Labels ---
features_df["label"] = features_df["label"] - 1  # Convert labels to 0‚Äì2
y = features_df["label"].values
y_cat = to_categorical(y, num_classes=3)

# --- Step 3: Separate Modalities for GCCA ---
acc_features = features_df.filter(regex="^acc_").values
bvp_features = features_df.filter(regex="^bvp_").values
temp_features = features_df.filter(regex="^temp_").values

# --- Step 4: Normalize Each View ---
scaler = StandardScaler()
acc_scaled = scaler.fit_transform(acc_features)
bvp_scaled = scaler.fit_transform(bvp_features)
temp_scaled = scaler.fit_transform(temp_features)

# --- Step 5: Apply GCCA (Multiset CCA) ---
gcca = GCCA(n_components=5)
views = [acc_scaled, bvp_scaled, temp_scaled]
gcca_fused = gcca.fit_transform(views)

# Concatenate the fused views into one feature matrix
X_fused = np.concatenate(gcca_fused, axis=1)  # Shape: (samples, 30)

# --- Step 6: Reshape for BiLSTM ---
X_seq = X_fused.reshape((X_fused.shape[0], X_fused.shape[1], 1))  # (samples, timesteps=30, features=1)

# --- Step 7: Train-Test Split ---
X_train_seq, X_test_seq, y_train_cat, y_test_cat, y_train, y_test = train_test_split(
    X_seq, y_cat, y, test_size=0.2, stratify=y, random_state=42
)

# --- Step 8: BiLSTM Embedding Model ---
input_layer = Input(shape=(X_seq.shape[1], 1))
x = Bidirectional(LSTM(64, return_sequences=True))(input_layer)
x = LSTM(32)(x)
dense_output = Dense(32, activation='relu')(x)

feature_extractor = Model(inputs=input_layer, outputs=dense_output)
features_train = feature_extractor.predict(X_train_seq)
features_test = feature_extractor.predict(X_test_seq)

# --- Step 9: XGBoost Classifier ---
xgb_model = XGBClassifier(
    objective='multi:softprob',
    num_class=3,
    n_estimators=100,
    eval_metric='mlogloss',
    use_label_encoder=False
)
xgb_model.fit(features_train, y_train)

# --- Step 10: Evaluate ---
y_pred = xgb_model.predict(features_test)
print("‚úÖ Classification Report:\n", classification_report(y_test, y_pred))
print("üìä Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

conda create -n mvlearn python=3.9
conda activate mvlearn
pip install mvlearn

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from mvlearn.embed import GCCA

# --- Step 1: Load Extracted Features ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")

# --- Step 2: Prepare Labels ---
features_df["label"] = features_df["label"] - 1  # Convert labels to 0‚Äì2
y = features_df["label"].values

# --- Step 3: Separate Modalities for GCCA ---
acc_features = features_df.filter(regex="^acc_").values
bvp_features = features_df.filter(regex="^bvp_").values
temp_features = features_df.filter(regex="^temp_").values

# --- Step 4: Normalize Each View ---
scaler = StandardScaler()
acc_scaled = scaler.fit_transform(acc_features)
bvp_scaled = scaler.fit_transform(bvp_features)
temp_scaled = scaler.fit_transform(temp_features)

# --- Step 5: Apply GCCA (Multiset CCA) ---
gcca = GCCA(n_components=15)
views = [acc_scaled, bvp_scaled, temp_scaled]
gcca_fused = gcca.fit_transform(views)

# Concatenate the fused views into one feature matrix
X_fused = np.concatenate(gcca_fused, axis=1)  # Shape: (samples, 15)

# --- Step 6: Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(
    X_fused, y, test_size=0.2, stratify=y, random_state=42
)

# --- Step 7: Train Random Forest ---
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# --- Step 8: Evaluate ---
y_pred = rf.predict(X_test)
print("‚úÖ Classification Report:\n", classification_report(y_test, y_pred))
print("üìä Confusion Matrix:\n", confusion_matrix(y_test, y_pred))



import pandas as pd
import numpy as np
from scipy.signal import stft
from scipy.stats import linregress

# --- Step 1: Load Data ---
df = pd.read_csv("combined1.csv")
df = df.drop(columns=["Unnamed: 0"], errors='ignore')

# --- Step 2: Define windowing parameters ---
window_size = 30  # seconds
sampling_rate = 1  # Hz; change if needed
samples_per_window = window_size * sampling_rate

# --- Step 3: Feature Extraction Functions ---
def extract_statistical_features(segment):
    features = {}
    for col in segment.columns:
        x = segment[col].values
        slope = linregress(range(len(x)), x).slope
        features[f"{col}_mean"] = np.mean(x)
        features[f"{col}_std"] = np.std(x)
        features[f"{col}_slope"] = slope
    return features

def extract_stft_features(segment):
    features = {}
    for col in segment.columns:
        x = segment[col].values
        f, t, Zxx = stft(x, fs=sampling_rate, nperseg=min(8, len(x)))
        magnitude = np.abs(Zxx)
        if magnitude.size > 0:
            features[f"{col}_stft_mean"] = np.mean(magnitude)
            features[f"{col}_stft_max"] = np.max(magnitude)
        else:
            features[f"{col}_stft_mean"] = 0
            features[f"{col}_stft_max"] = 0
    return features

# --- Step 4: Apply windowing and extract features ---
feature_rows = []
labels = []
subjects = []

sensor_columns = [col for col in df.columns if col not in ["timestamp", "label", "subject"]]

for subject in df["subject"].unique():
    subject_df = df[df["subject"] == subject].reset_index(drop=True)
    for i in range(0, len(subject_df) - samples_per_window + 1, samples_per_window):
        window = subject_df.iloc[i:i+samples_per_window]
        if window["label"].nunique() == 1:
            stat_features = extract_statistical_features(window[sensor_columns])
            stft_features = extract_stft_features(window[sensor_columns])
            feature_row = {**stat_features, **stft_features}
            feature_rows.append(feature_row)
            labels.append(window["label"].iloc[0])
            subjects.append(subject)

# --- Step 5: Final Feature Matrix ---
features_df = pd.DataFrame(feature_rows)
features_df["label"] = labels
features_df["subject"] = subjects
features_df.to_csv("wesad_features_stft_30s_1.csv", index=False)

print("‚úÖ Features extracted and saved. Shape:", features_df.shape)

!pip install mvlearn

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from mvlearn.embed import GCCA

# --- Step 1: Load Extracted Features ---
features_df = pd.read_csv("wesad_features_stft_30s.csv")

# --- Step 2: Prepare Labels ---
features_df["label"] = features_df["label"] - 1  # Convert labels to 0,1,2
y = features_df["label"].values

# --- Step 3: Separate Modalities ---
acc_features = features_df.filter(regex="^acc_").values
bvp_features = features_df.filter(regex="^bvp_").values
temp_features = features_df.filter(regex="^temp_").values

# --- Step 4: Normalize Each Modality ---
scaler = StandardScaler()
acc_scaled = scaler.fit_transform(acc_features)
bvp_scaled = scaler.fit_transform(bvp_features)
temp_scaled = scaler.fit_transform(temp_features)

# --- Step 5: Apply GCCA for Fusion ---
gcca = GCCA(n_components=5)
views = [acc_scaled, bvp_scaled, temp_scaled]
gcca_fused = gcca.fit_transform(views)

# Concatenate GCCA outputs
X_fused = np.concatenate(gcca_fused, axis=1)  # Shape: (samples, 15)

# --- Step 6: Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(
    X_fused, y, test_size=0.2, stratify=y, random_state=42
)

# --- Step 7: Train Random Forest ---
rf = RandomForestClassifier(n_estimators=150, random_state=42)
rf.fit(X_train, y_train)

# --- Step 8: Evaluate ---
y_pred = rf.predict(X_test)
print("‚úÖ Classification Report:\n", classification_report(y_test, y_pred))
print("üìä Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

import pandas as pd
import numpy as np
from sklearn.feature_selection import f_classif
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.ensemble import RandomForestClassifier

# --- Load Extracted Features ---
df = pd.read_csv("wesad_features_stft_30s.csv")
df["label"] = df["label"] - 1  # Make labels 0-indexed (0,1,2)

# --- Separate Modalities ---
y = df["label"].values
acc = df.filter(regex="^acc_")
bvp = df.filter(regex="^bvp_")
temp = df.filter(regex="^temp_")

# --- Normalize Each Modality ---
scaler = StandardScaler()
acc = pd.DataFrame(scaler.fit_transform(acc), columns=acc.columns)
bvp = pd.DataFrame(scaler.fit_transform(bvp), columns=bvp.columns)
temp = pd.DataFrame(scaler.fit_transform(temp), columns=temp.columns)

# --- Feature Selection (Supervised) ---
def select_top_features(X, y, top_k):
    scores, _ = f_classif(X, y)
    ranked_idx = np.argsort(scores)[::-1][:top_k]
    return X.iloc[:, ranked_idx]

top_k = 10  # Features per modality
acc_sel = select_top_features(acc, y, top_k)
bvp_sel = select_top_features(bvp, y, top_k)
temp_sel = select_top_features(temp, y, top_k)

# --- Fuse Features ---
X_fused = pd.concat([acc_sel, bvp_sel, temp_sel], axis=1)

# --- Train/Test Split ---
X_train, X_test, y_train, y_test = train_test_split(X_fused, y, test_size=0.2, stratify=y, random_state=42)

# --- Random Forest Classifier ---
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# --- Evaluate ---
y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

import pandas as pd
import numpy as np
from sklearn.feature_selection import f_classif
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.svm import SVC

# --- Load Extracted Features ---
df = pd.read_csv("/content/wesad_features_stft_30s_1.csv")
df["label"] = df["label"] - 1  # Make labels 0-indexed (0,1,2)

# --- Separate Modalities ---
y = df["label"].values
acc = df.filter(regex="^acc_")
bvp = df.filter(regex="^bvp_")
temp = df.filter(regex="^temp_")
eda= df.filter(regex="^eda_")

# --- Normalize Each Modality ---
scaler = StandardScaler()
acc = pd.DataFrame(scaler.fit_transform(acc), columns=acc.columns)
bvp = pd.DataFrame(scaler.fit_transform(bvp), columns=bvp.columns)
temp = pd.DataFrame(scaler.fit_transform(temp), columns=temp.columns)
eda = pd.DataFrame(scaler.fit_transform(eda), columns=eda.columns)
# --- Supervised Feature Selection ---
def select_top_features(X, y, top_k):
    scores, _ = f_classif(X, y)
    ranked_idx = np.argsort(scores)[::-1][:top_k]
    return X.iloc[:, ranked_idx]

top_k = 10  # Features per modality
acc_sel = select_top_features(acc, y, top_k)
bvp_sel = select_top_features(bvp, y, top_k)
temp_sel = select_top_features(temp, y, top_k)
eda_sel = select_top_features(eda, y, top_k)
# --- Feature Fusion ---
X_fused = pd.concat([acc_sel, bvp_sel, temp_sel,eda_sel], axis=1)

# --- Train/Test Split ---
X_train, X_test, y_train, y_test = train_test_split(X_fused, y, test_size=0.2, stratify=y, random_state=42)

# --- SVM Classifier ---
clf = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)
clf.fit(X_train, y_train)

# --- Evaluation ---
y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

import pandas as pd
import numpy as np
from sklearn.feature_selection import f_classif
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# --- Load Extracted Features ---
df = pd.read_csv("/content/wesad_features_stft_30s_1.csv")
df["label"] = df["label"] - 1  # Make labels 0-indexed (0,1,2)

# --- Separate Modalities ---
y = df["label"].values
acc = df.filter(regex="^acc_")
bvp = df.filter(regex="^bvp_")
temp = df.filter(regex="^temp_")
eda = df.filter(regex="^eda_")  # ‚úÖ Fixed assignment

# --- Normalize Each Modality ---
scaler = StandardScaler()
acc = pd.DataFrame(scaler.fit_transform(acc), columns=acc.columns)
bvp = pd.DataFrame(scaler.fit_transform(bvp), columns=bvp.columns)
temp = pd.DataFrame(scaler.fit_transform(temp), columns=temp.columns)
eda = pd.DataFrame(scaler.fit_transform(eda), columns=eda.columns)

# --- Supervised Feature Selection ---
def select_top_features(X, y, top_k):
    scores, _ = f_classif(X, y)
    ranked_idx = np.argsort(scores)[::-1][:top_k]
    return X.iloc[:, ranked_idx]

top_k = 10  # Features per modality
acc_sel = select_top_features(acc, y, top_k)
bvp_sel = select_top_features(bvp, y, top_k)
temp_sel = select_top_features(temp, y, top_k)
eda_sel = select_top_features(eda, y, top_k)

# --- Feature Fusion ---
X_fused = pd.concat([acc_sel, bvp_sel, temp_sel, eda_sel], axis=1)

# --- Train/Test Split ---
X_train, X_test, y_train, y_test = train_test_split(X_fused, y, test_size=0.2, stratify=y, random_state=42)

# --- Random Forest Classifier ---
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train, y_train)

# --- Evaluation ---
y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# --- Print Top Discriminative Features ---
importances = clf.feature_importances_
feature_names = X_fused.columns

# Sort feature importances in descending order
sorted_idx = np.argsort(importances)[::-1]

print("\nTop 20 Most Discriminative Features:\n")
for i in range(20):
    print(f"{i+1}. {feature_names[sorted_idx[i]]}: {importances[sorted_idx[i]]:.4f}")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix

# --- Load Data ---
df = pd.read_csv("/content/wesad_features_stft_30s_1.csv")
df["label"] = df["label"] - 1  # Ensure labels are 0-indexed (0,1,2)
y = df["label"].values
X = df.drop(columns=["label"])

# --- Standardize Features ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X = pd.DataFrame(X_scaled, columns=X.columns)

# --- Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# --- Train Random Forest ---
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# --- Predict and Evaluate ---
y_pred = rf.predict(X_test)
print(classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# --- Feature Importances ---
importances = rf.feature_importances_
indices = np.argsort(importances)[::-1]
top_k = 20  # Top 20 most important features

# --- Plot Top Features ---
plt.figure(figsize=(12, 6))
plt.title("Top 20 Most Discriminative Features (Random Forest)")
plt.bar(range(top_k), importances[indices[:top_k]], align="center")
plt.xticks(range(top_k), X.columns[indices[:top_k]], rotation=90)
plt.ylabel("Feature Importance")
plt.tight_layout()
plt.grid(True)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.metrics import classification_report, confusion_matrix

# --- Load Data ---
df = pd.read_csv("/content/wesad_features_stft_30s_1.csv")
df["label"] = df["label"] - 1  # Ensure labels are 0-indexed (0,1,2)
y = df["label"].values
X = df.drop(columns=["label"])

# --- Standardize Features ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)

# --- F-test Feature Selection ---
k = 20  # Number of top features to select
selector = SelectKBest(score_func=f_classif, k=k)
X_new = selector.fit_transform(X_scaled, y)
selected_features = X.columns[selector.get_support()].tolist()
print(f"Selected Features by F-test:\n{selected_features}")

# --- Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, stratify=y, random_state=42)

# --- Train Random Forest ---
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# --- Predict and Evaluate ---
y_pred = rf.predict(X_test)
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# --- Feature Importances ---
importances = rf.feature_importances_
indices = np.argsort(importances)[::-1]

# --- Plot Top Features ---
plt.figure(figsize=(12, 6))
plt.title("Top 20 Features (F-test selected ‚Üí Random Forest importance)")
plt.bar(range(k), importances[indices], align="center")
plt.xticks(range(k), np.array(selected_features)[indices], rotation=90)
plt.ylabel("Feature Importance")
plt.tight_layout()
plt.grid(True)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.cross_decomposition import CCA
from sklearn.metrics import classification_report, confusion_matrix

# --- Load Data ---
df = pd.read_csv("/content/wesad_features_stft_30s_1.csv")
df["label"] = df["label"] - 1  # Ensure 0-indexed labels
y = df["label"].values

# --- Split modality views ---
acc_cols = [col for col in df.columns if col.startswith("acc_")]
bvp_cols = [col for col in df.columns if col.startswith("bvp_")]
temp_cols = [col for col in df.columns if col.startswith("temp_")]
eda_cols = [col for col in df.columns if col.startswith("eda_")]

X_acc = df[acc_cols]
X_bvp = df[bvp_cols]
X_temp = df[temp_cols]
X_eda = df[eda_cols]

# --- Standardize each view ---
X_acc = StandardScaler().fit_transform(X_acc)
X_bvp = StandardScaler().fit_transform(X_bvp)
X_temp = StandardScaler().fit_transform(X_temp)
X_eda = StandardScaler().fit_transform(X_eda)

# --- Apply CCA for pairwise view combinations ---
cca_ab = CCA(n_components=5).fit(X_acc, X_bvp)
cca_bt = CCA(n_components=5).fit(X_bvp, X_temp)
cca_te = CCA(n_components=5).fit(X_temp, X_eda)
cca_ea = CCA(n_components=5).fit(X_eda, X_acc)

cca_ab_X, _ = cca_ab.transform(X_acc, X_bvp)
cca_bt_X, _ = cca_bt.transform(X_bvp, X_temp)
cca_te_X, _ = cca_te.transform(X_temp, X_eda)
cca_ea_X, _ = cca_ea.transform(X_eda, X_acc)

# --- Concatenate all pairwise CCA outputs ---
X_fused = np.concatenate([cca_ab_X, cca_bt_X, cca_te_X, cca_ea_X], axis=1)

# --- Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(X_fused, y, test_size=0.2, stratify=y, random_state=42)

# --- Train Random Forest ---
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)

# --- Evaluation ---
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# --- Feature Importances Plot ---
importances = rf.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(10, 5))
plt.title("Top CCA-Fused Features (Random Forest)")
plt.bar(range(X_fused.shape[1]), importances[indices], align="center")
plt.xticks(range(X_fused.shape[1]), [f"CCA_{i}" for i in indices], rotation=90)
plt.ylabel("Feature Importance")
plt.tight_layout()
plt.grid(True)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import f_classif
from sklearn.metrics import classification_report, confusion_matrix

# --- Load and preprocess data ---
df = pd.read_csv("/content/wesad_features_stft_30s_1.csv")
df["label"] = df["label"] - 1  # Ensure 0-indexed labels
X = df.drop(columns=["label"])
y = df["label"].values

# --- Standardize features ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)

# --- F-test (Feature correlation with label) ---
F_scores, p_values = f_classif(X_scaled_df, y)
f_df = pd.DataFrame({
    "Feature": X.columns,
    "F_score": F_scores,
    "p_value": p_values
}).sort_values(by="F_score", ascending=False)

# --- Train-test split ---
X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.2, stratify=y, random_state=42)

# --- Train Random Forest ---
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# --- Predict & evaluate ---
y_pred = rf.predict(X_test)
print("\n--- Classification Report ---")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# --- Random Forest feature importances ---
rf_importances = rf.feature_importances_
rf_df = pd.DataFrame({
    "Feature": X.columns,
    "RF_Importance": rf_importances
}).sort_values(by="RF_Importance", ascending=False)

# --- Merge both F-test and RF importance ---
combined_df = pd.merge(f_df, rf_df, on="Feature")
combined_df = combined_df.sort_values(by="F_score", ascending=False)

# --- Plot Top Features by F-score and RF Importance ---
top_k = 20
top_features = combined_df.head(top_k)

plt.figure(figsize=(14, 6))
plt.subplot(1, 2, 1)
plt.title("Top 20 Features (F-test)")
plt.barh(top_features["Feature"], top_features["F_score"], color='skyblue')
plt.gca().invert_yaxis()
plt.xlabel("F-score")

plt.subplot(1, 2, 2)
plt.title("Top 20 Features (Random Forest Importance)")
plt.barh(top_features["Feature"], top_features["RF_Importance"], color='salmon')
plt.gca().invert_yaxis()
plt.xlabel("RF Importance")

plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import f_classif
from sklearn.metrics import classification_report, confusion_matrix

# --- Load and preprocess data ---
df = pd.read_csv("/content/wesad_features_stft_30s_1.csv")
df["label"] = df["label"] - 1  # Ensure 0-indexed labels

# --- Remove EDA features (those containing 'eda' or 'EDA') ---
X = df.drop(columns=["label"])
X = X.loc[:, ~X.columns.str.contains('eda', case=False)]
y = df["label"].values

# --- Standardize features ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)

# --- F-test (Feature correlation with label) ---
F_scores, p_values = f_classif(X_scaled_df, y)
f_df = pd.DataFrame({
    "Feature": X.columns,
    "F_score": F_scores,
    "p_value": p_values
}).sort_values(by="F_score", ascending=False)

# --- Train-test split ---
X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.2, stratify=y, random_state=42)

# --- Train Random Forest ---
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# --- Predict & evaluate ---
y_pred = rf.predict(X_test)
print("\n--- Classification Report ---")
print(classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# --- Random Forest feature importances ---
rf_importances = rf.feature_importances_
rf_df = pd.DataFrame({
    "Feature": X.columns,
    "RF_Importance": rf_importances
}).sort_values(by="RF_Importance", ascending=False)

# --- Merge both F-test and RF importance ---
combined_df = pd.merge(f_df, rf_df, on="Feature")
combined_df = combined_df.sort_values(by="F_score", ascending=False)

# --- Plot Top Features by F-score and RF Importance ---
top_k = 20
top_features = combined_df.head(top_k)

plt.figure(figsize=(14, 6))
plt.subplot(1, 2, 1)
plt.title("Top 20 Features (F-test, EDA excluded)")
plt.barh(top_features["Feature"], top_features["F_score"], color='skyblue')
plt.gca().invert_yaxis()
plt.xlabel("F-score")

plt.subplot(1, 2, 2)
plt.title("Top 20 Features (Random Forest Importance, EDA excluded)")
plt.barh(top_features["Feature"], top_features["RF_Importance"], color='salmon')
plt.gca().invert_yaxis()
plt.xlabel("RF Importance")

plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import f_classif
from sklearn.metrics import classification_report, confusion_matrix

# --- Load Data ---
df = pd.read_csv("/content/wesad_features_stft_30s_1.csv")
df["label"] = df["label"] - 1  # Ensure labels are 0-indexed

# --- Filter only TEMP and EDA features ---
feature_cols = [col for col in df.columns if ("temp" in col.lower() or "eda" in col.lower()) and "label" not in col.lower()]
X = df[feature_cols]
y = df["label"].values

# --- Standardize ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)

# --- F-test Feature Scores ---
F_scores, p_values = f_classif(X_scaled_df, y)
f_df = pd.DataFrame({
    "Feature": X.columns,
    "F_score": F_scores,
    "p_value": p_values
}).sort_values(by="F_score", ascending=False)

print("\n--- Top Features by F-test ---")
print(f_df)

# --- Train/Test Split ---
X_train, X_test, y_train, y_test = train_test_split(X_scaled_df, y, test_size=0.2, stratify=y, random_state=42)

# --- Random Forest ---
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)

# --- Evaluation ---
print("\n--- Classification Report ---")
print(classification_report(y_test, y_pred))

print("\n--- Confusion Matrix ---")
print(confusion_matrix(y_test, y_pred))

# --- Feature Importances ---
importances = rf.feature_importances_
indices = np.argsort(importances)[::-1]
top_k = min(10, len(importances))  # Adjust if fewer features

# --- Plot Top Features ---
plt.figure(figsize=(10, 5))
plt.title("Top Discriminative TEMP & EDA Features (Random Forest)")
plt.bar(range(top_k), importances[indices[:top_k]], align="center")
plt.xticks(range(top_k), X.columns[indices[:top_k]], rotation=90)
plt.ylabel("Feature Importance")
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.metrics import classification_report, confusion_matrix

# --- Load Data ---
df = pd.read_csv("/content/wesad_features_stft_30s_1.csv")
df["label"] = df["label"] - 1  # Convert labels to 0,1,2
y = df["label"].values

# --- Define View-Specific Feature Groups ---
eda_cols = [col for col in df.columns if "eda" in col.lower()]
bvp_cols = [col for col in df.columns if "bvp" in col.lower()]
acc_cols = [col for col in df.columns if "acc" in col.lower()]
temp_cols = [col for col in df.columns if "temp" in col.lower()]

# --- Select Top-K Features Per View ---
def select_top_k(view_data, labels, k=3):
    selector = SelectKBest(score_func=f_classif, k=k)
    selector.fit(view_data, labels)
    selected_cols = view_data.columns[selector.get_support()]
    return list(selected_cols)

selected_eda = select_top_k(df[eda_cols], y, k=3)
selected_bvp = select_top_k(df[bvp_cols], y, k=3)
selected_acc = select_top_k(df[acc_cols], y, k=2)
selected_temp = select_top_k(df[temp_cols], y, k=2)

# --- Combine All Selected Features ---
selected_features = selected_eda + selected_bvp + selected_acc + selected_temp
X = df[selected_features]

# --- Standardize ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X = pd.DataFrame(X_scaled, columns=X.columns)

# --- Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# --- Train Random Forest ---
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# --- Predict and Evaluate ---
y_pred = rf.predict(X_test)
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# --- Plot Feature Importances ---
importances = rf.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(10, 5))
plt.title("Top View-Specific Features (Random Forest Importance)")
plt.bar(range(len(selected_features)), importances[indices], align="center")
plt.xticks(range(len(selected_features)), np.array(selected_features)[indices], rotation=90)
plt.ylabel("Feature Importance")
plt.tight_layout()
plt.grid(True)
plt.show()



import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Bidirectional, Dense
from tensorflow.keras.utils import to_categorical
from xgboost import XGBClassifier

# --- Load Features ---
df = pd.read_csv("wesad_features_stft_30s_1.csv")
df["label"] = df["label"] - 1  # convert to 0-indexed labels

# --- Separate Labels and Subject Info ---
labels = df["label"].values
subjects = df["subject"].values

# --- Drop metadata columns ---
X = df.drop(columns=["label", "subject", "timestamp"], errors='ignore')

# --- Normalize Features ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# --- Reshape to Sequences for LSTM ---
# Assuming each sample is independent: reshape as (samples, timesteps=1, features)
X_seq = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))

# --- Split Train/Test ---
X_train_seq, X_test_seq, y_train, y_test = train_test_split(X_seq, labels, test_size=0.2, stratify=labels, random_state=42)

# --- LSTM Model to Extract Embeddings ---
input_layer = Input(shape=(X_train_seq.shape[1], X_train_seq.shape[2]))
lstm_out = Bidirectional(LSTM(64, return_sequences=False))(input_layer)
dense = Dense(32, activation='relu')(lstm_out)
embedding_model = Model(inputs=input_layer, outputs=dense)
embedding_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')

# --- Train only to get LSTM embeddings ---
embedding_model.fit(X_train_seq, y_train, epochs=10, batch_size=32, verbose=1)

# --- Extract LSTM Embeddings ---
X_train_embed = embedding_model.predict(X_train_seq)
X_test_embed = embedding_model.predict(X_test_seq)

# --- XGBoost Classifier ---
xgb = XGBClassifier(n_estimators=100, max_depth=5, learning_rate=0.1, use_label_encoder=False, eval_metric='mlogloss')
xgb.fit(X_train_embed, y_train)

# --- Evaluate ---
y_pred = xgb.predict(X_test_embed)
print("üìä Classification Report:\n", classification_report(y_test, y_pred))
print("üìâ Confusion Matrix:\n", confusion_matrix(y_test, y_pred))



import pandas as pd
import numpy as np
from sklearn.feature_selection import f_classif
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.utils import to_categorical

# --- Load Extracted Features ---
df = pd.read_csv("wesad_features_stft_30s.csv")
df["label"] = df["label"] - 1  # Labels: 0, 1, 2

# --- Extract Modalities ---
y = df["label"].values
acc = df.filter(regex="^acc_")
bvp = df.filter(regex="^bvp_")
temp = df.filter(regex="^temp_")

# --- Normalize Each Modality ---
scaler = StandardScaler()
acc = pd.DataFrame(scaler.fit_transform(acc), columns=acc.columns)
bvp = pd.DataFrame(scaler.fit_transform(bvp), columns=bvp.columns)
temp = pd.DataFrame(scaler.fit_transform(temp), columns=temp.columns)

# --- Label-aware Feature Selection ---
def select_top_features(X, y, top_k):
    scores, _ = f_classif(X, y)
    top_idx = np.argsort(scores)[::-1][:top_k]
    return X.iloc[:, top_idx]

top_k = 5
acc_sel = select_top_features(acc, y, top_k)
bvp_sel = select_top_features(bvp, y, top_k)
temp_sel = select_top_features(temp, y, top_k)

# --- Fuse Selected Features ---
X_fused = pd.concat([acc_sel, bvp_sel, temp_sel], axis=1)

# --- Train/Test Split ---
X_train, X_test, y_train, y_test = train_test_split(X_fused, y, test_size=0.2, stratify=y, random_state=42)

# --- Reshape for LSTM [samples, timesteps, features] ---
X_train_lstm = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))
X_test_lstm = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))
y_train_cat = to_categorical(y_train, num_classes=3)
y_test_cat = to_categorical(y_test, num_classes=3)

# --- Build LSTM Model ---
model = Sequential()
model.add(LSTM(32, input_shape=(1, X_train.shape[1]), activation='tanh'))
model.add(Dense(16, activation='relu'))
model.add(Dense(3, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X_train_lstm, y_train_cat, epochs=30, batch_size=32, validation_data=(X_test_lstm, y_test_cat), verbose=1)

# --- Evaluate ---
y_pred = model.predict(X_test_lstm)
y_pred_classes = np.argmax(y_pred, axis=1)
print(classification_report(y_test, y_pred_classes))
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred_classes))



import pandas as pd
import numpy as np
from scipy.fft import fft
from scipy.stats import linregress
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Input
from sklearn.preprocessing import MinMaxScaler
from tqdm import tqdm

# --- Step 1: Load Data ---
df = pd.read_csv("combined.csv")
df = df.drop(columns=["Unnamed: 0"], errors='ignore')

# --- Step 2: Parameters ---
window_size = 30  # seconds
sampling_rate = 1  # 1 Hz
samples_per_window = window_size * sampling_rate

sensor_columns = [col for col in df.columns if col not in ["timestamp", "label", "subject"]]
modalities = {
    "GSR": [col for col in sensor_columns if "eda" in col.lower() or "gsr" in col.lower()],
    "BVP": [col for col in sensor_columns if "bvp" in col.lower() or "hr" in col.lower()],
    "TEMP": [col for col in sensor_columns if "temp" in col.lower()]
}

# --- Step 3: Feature Functions ---
def extract_statistical_features(segment):
    features = {}
    for col in segment.columns:
        x = segment[col].values
        slope = linregress(range(len(x)), x).slope
        features[f"{col}_mean"] = np.mean(x)
        features[f"{col}_std"] = np.std(x)
        features[f"{col}_slope"] = slope
    return features

def extract_fft_features(segment):
    features = {}
    for col in segment.columns:
        x = segment[col].values
        fft_vals = np.abs(fft(x))
        top_freqs = np.sort(fft_vals[1:])[-3:]  # Skip DC
        for i, val in enumerate(top_freqs):
            features[f"{col}_fft_{i+1}"] = val
    return features

def build_lstm_model(input_shape):
    model = Sequential([
        Input(shape=input_shape),
        LSTM(32, return_sequences=False),
        Dense(16, activation='relu')
    ])
    return model

# --- Step 4: Extract Features per Window per Modality ---
all_feature_rows = []
all_labels = []
all_subjects = []

lstm_models = {mod: None for mod in modalities.keys()}
scalers = {mod: MinMaxScaler() for mod in modalities.keys()}

print("‚è≥ Extracting features...")

for subject in tqdm(df["subject"].unique()):
    subject_df = df[df["subject"] == subject].reset_index(drop=True)

    for i in range(0, len(subject_df) - samples_per_window + 1, samples_per_window):
        window = subject_df.iloc[i:i+samples_per_window]
        if window["label"].nunique() != 1:
            continue

        label = window["label"].iloc[0]
        feature_dict = {}

        # Process each modality separately
        for mod_name, mod_cols in modalities.items():
            if not mod_cols:
                continue
            mod_segment = window[mod_cols].copy()

            # Normalize
            mod_segment_scaled = scalers[mod_name].fit_transform(mod_segment)

            # LSTM embedding
            mod_segment_seq = np.expand_dims(mod_segment_scaled, axis=0)
            if lstm_models[mod_name] is None:
                input_shape = (samples_per_window, len(mod_cols))
                lstm_models[mod_name] = build_lstm_model(input_shape)
            lstm_embedding = lstm_models[mod_name].predict(mod_segment_seq, verbose=0)[0]

            # Collect LSTM embedding
            for j, val in enumerate(lstm_embedding):
                feature_dict[f"{mod_name}_lstm_{j+1}"] = val

            # Add statistical + FFT features
            stat_feats = extract_statistical_features(mod_segment)
            fft_feats = extract_fft_features(mod_segment)
            feature_dict.update({f"{mod_name}_{k}": v for k, v in {**stat_feats, **fft_feats}.items()})

        all_feature_rows.append(feature_dict)
        all_labels.append(label)
        all_subjects.append(subject)

# --- Step 5: Combine All Features ---
features_df = pd.DataFrame(all_feature_rows)
features_df["label"] = all_labels
features_df["subject"] = all_subjects

# Save to CSV
features_df.to_csv("wesad_multimodal_features.csv", index=False)
print("‚úÖ Feature extraction completed. Shape:", features_df.shape)

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.cross_decomposition import CCA
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from tqdm import tqdm

# --- Load the multimodal LSTM + statistical features ---
df = pd.read_csv("wesad_multimodal_features.csv")

# --- Label encoding ---
le = LabelEncoder()
df['label'] = le.fit_transform(df['label'])

# --- Define modalities ---
modalities = {

    "BVP": [col for col in df.columns if col.startswith("BVP_lstm_")],
    "TEMP": [col for col in df.columns if col.startswith("TEMP_lstm_")]
}

# --- Extract per-modality feature matrices ---
X_modalities = {mod: df[cols].values for mod, cols in modalities.items()}
y = df["label"].values

# --- Standardize each modality ---
scalers = {mod: StandardScaler().fit(X) for mod, X in X_modalities.items()}
X_modalities = {mod: scalers[mod].transform(X) for mod, X in X_modalities.items()}

# --- Supervised MCCA using CCA approximation ---
# We'll apply CCA between each modality and the label to make it 'supervised'
cca_components = 10  # dimensionality of shared subspace
cca_models = {}
X_projected = []

for mod, X_mod in X_modalities.items():
    # Fit CCA between modality and one-hot labels
    y_onehot = np.eye(len(np.unique(y)))[y]
    cca = CCA(n_components=cca_components)
    X_c, _ = cca.fit_transform(X_mod, y_onehot)
    X_projected.append(X_c)
    cca_models[mod] = cca

# --- Concatenate projected modality features ---
X_final = np.concatenate(X_projected, axis=1)

# --- Train/test split ---
X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)

# --- Classifier ---
clf = RandomForestClassifier(n_estimators=200, random_state=42)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

# --- Evaluation ---
print("üìä Classification Report:\n")
print(classification_report(y_test, y_pred, target_names=le.classes_))

print([col for col in df.columns if 'gsr' in col.lower()])

modalities = {
    "BVP": [col for col in df.columns if col.startswith("BVP_lstm_")],
    "TEMP": [col for col in df.columns if col.startswith("TEMP_lstm_")]
}

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectKBest, f_classif

# --- Step 1: Load Extracted Features ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")

# --- Step 2: Prepare Labels ---
features_df["label"] = features_df["label"] - 1  # Convert labels to 0‚Äì2
y = features_df["label"].values

# --- Step 3: Separate Features and Labels ---
X = features_df.drop(columns=["label"]).values
feature_names = features_df.drop(columns=["label"]).columns

# --- Step 4: Normalize Features ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# --- Step 5: ANOVA F-test for Feature Selection ---
# Keep top k features (you can adjust k, e.g., 50, 100, etc.)
k = 50
selector = SelectKBest(score_func=f_classif, k=k)
X_selected = selector.fit_transform(X_scaled, y)

# Get selected feature names (optional, for analysis)
selected_features = feature_names[selector.get_support()]

print(f"‚úÖ Selected {len(selected_features)} features using ANOVA F-test")

# --- Step 6: Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(
    X_selected, y, test_size=0.2, stratify=y, random_state=42
)

# --- Step 7: Train Random Forest ---
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# --- Step 8: Evaluate ---
y_pred = rf.predict(X_test)
print("‚úÖ Classification Report:\n", classification_report(y_test, y_pred))
print("üìä Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from scipy.stats import pearsonr

# --- Step 1: Load Extracted Features ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")

# --- Step 2: Prepare Labels ---
features_df["label"] = features_df["label"] - 1  # Convert labels to 0‚Äì2
y = features_df["label"].values

# --- Step 3: Separate Features ---
X = features_df.drop(columns=["label"])
feature_names = X.columns

# --- Step 4: Pearson Correlation Feature Selection ---
correlations = []
for col in feature_names:
    try:
        corr, pval = pearsonr(X[col], y)
        correlations.append((col, abs(corr), pval))
    except Exception:
        correlations.append((col, 0, 1.0))  # if constant feature

# Sort by absolute correlation strength
correlations.sort(key=lambda x: x[1], reverse=True)

# Keep top-k features (you can tune k)
k = 50
selected_features = [c[0] for c in correlations[:k]]

print(f"‚úÖ Top {k} features selected by Pearson correlation")

# --- Step 5: Normalize Features ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X[selected_features])

# --- Step 6: Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, stratify=y, random_state=42
)

# --- Step 7: Train Random Forest ---
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# --- Step 8: Evaluate ---
y_pred = rf.predict(X_test)
print("‚úÖ Classification Report:\n", classification_report(y_test, y_pred))
print("üìä Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import mutual_info_classif

# --- Step 1: Load Extracted Features ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")

# --- Step 2: Prepare Labels ---
features_df["label"] = features_df["label"] - 1  # Convert labels to 0‚Äì2
y = features_df["label"].values

# --- Step 3: Separate Features ---
X = features_df.drop(columns=["label"])
feature_names = X.columns

# --- Step 4: Compute Information Gain (Mutual Information) ---
mi_scores = mutual_info_classif(X, y, random_state=42)

# Rank features by information gain
mi_ranking = sorted(
    zip(feature_names, mi_scores), key=lambda x: x[1], reverse=True
)

# Keep top-k features (you can tune k)
k = 50
selected_features = [f for f, score in mi_ranking[:k]]

print("‚úÖ Top features by Information Gain:")
for f, score in mi_ranking[:10]:
    print(f"{f}: {score:.4f}")

# --- Step 5: Normalize Selected Features ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X[selected_features])

# --- Step 6: Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, stratify=y, random_state=42
)

# --- Step 7: Train Random Forest ---
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# --- Step 8: Evaluate ---
y_pred = rf.predict(X_test)
print("\n‚úÖ Classification Report:\n", classification_report(y_test, y_pred))
print("üìä Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.feature_selection import f_classif, mutual_info_classif
from scipy.stats import pearsonr
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

# --- Load Data ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")
features_df["label"] = features_df["label"] - 1
y = features_df["label"].values
X = features_df.drop(columns=["label"])
feature_names = X.columns
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# -------------------------------
# 1. Pearson Correlation
# -------------------------------
pearson_scores = []
for col in feature_names:
    try:
        corr, _ = pearsonr(X[col], y)
        pearson_scores.append(abs(corr))
    except:
        pearson_scores.append(0)
pearson_ranking = np.argsort(pearson_scores)[::-1]

# -------------------------------
# 2. ANOVA F-test
# -------------------------------
f_scores, _ = f_classif(X_scaled, y)
f_ranking = np.argsort(f_scores)[::-1]

# -------------------------------
# 3. Information Gain (Mutual Info)
# -------------------------------
mi_scores = mutual_info_classif(X_scaled, y, random_state=42)
mi_ranking = np.argsort(mi_scores)[::-1]

# -------------------------------
# 4. Random Forest Feature Importance
# -------------------------------
rf = RandomForestClassifier(n_estimators=200, random_state=42)
rf.fit(X_scaled, y)
rf_importances = rf.feature_importances_
rf_ranking = np.argsort(rf_importances)[::-1]

# -------------------------------
# Plot Comparison of Rankings
# -------------------------------
top_k = 20  # top features to compare
plt.figure(figsize=(12,6))

plt.plot(range(top_k), np.array(pearson_scores)[pearson_ranking[:top_k]], label="Pearson Correlation")
plt.plot(range(top_k), f_scores[f_ranking[:top_k]], label="ANOVA F-test")
plt.plot(range(top_k), mi_scores[mi_ranking[:top_k]], label="Information Gain")
plt.plot(range(top_k), rf_importances[rf_ranking[:top_k]], label="Random Forest Importance")

plt.xlabel("Top-k Features (ranked)")
plt.ylabel("Score / Importance")
plt.title("Feature Selection Comparison (Top-20 Features)")
plt.legend()
plt.grid(True)
plt.show()

!pip install numpy==1.26.4 --upgrade --force-reinstall

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from mvlearn.embed import CCA  # for 2-view
from mvlearn.embed import MCCA  # for multi-view

# --- Step 1: Load Extracted Features ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")

# --- Step 2: Prepare Labels ---
features_df["label"] = features_df["label"] - 1  # Convert labels to 0‚Äì2
y = features_df["label"].values

# --- Step 3: Separate Modalities ---
acc_features = features_df.filter(regex="^acc_").values
bvp_features = features_df.filter(regex="^bvp_").values
temp_features = features_df.filter(regex="^temp_").values

# --- Step 4: Normalize Each Modality ---
scaler = StandardScaler()
acc_scaled = scaler.fit_transform(acc_features)
bvp_scaled = scaler.fit_transform(bvp_features)
temp_scaled = scaler.fit_transform(temp_features)

# --- Step 5: Apply Multiset CCA (MCCA) ---
mcca = MCCA(n_components=15, regs=None)  # regs=None means standard CCA
views = [acc_scaled, bvp_scaled, temp_scaled]
mcca_fused = mcca.fit_transform(views)

# Concatenate projected views into single feature matrix
X_fused = np.concatenate(mcca_fused, axis=1)

print("‚úÖ Shape after MCCA fusion:", X_fused.shape)

# --- Step 6: Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(
    X_fused, y, test_size=0.2, stratify=y, random_state=42
)

# --- Step 7: Train Random Forest ---
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# --- Step 8: Evaluate ---
y_pred = rf.predict(X_test)
print("‚úÖ Classification Report:\n", classification_report(y_test, y_pred))
print("üìä Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# 1. Uninstall any broken mvlearn
!pip uninstall -y mvlearn

# 2. Install mvlearn without dependencies
!pip install --no-deps git+https://github.com/mvlearn/mvlearn.git

# 3. Reinstall a modern matplotlib (so plotting still works)
!pip install matplotlib==3.7.1

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import f_classif, mutual_info_classif
from scipy.stats import pearsonr
from mvlearn.embed import MCCA

# --- Load Data ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")
features_df["label"] = features_df["label"] - 1
y = features_df["label"].values
X = features_df.drop(columns=["label"])
feature_names = X.columns
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# --- Split train/test ---
def split(X, y):
    return train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# --- 1. ANOVA F-test ---
f_scores, _ = f_classif(X_scaled, y)
top_k = 50
anova_idx = np.argsort(f_scores)[::-1][:top_k]
X_anova = X_scaled[:, anova_idx]

# --- 2. Pearson correlation ---
pearson_scores = np.array([abs(pearsonr(X.iloc[:,i], y)[0]) for i in range(X.shape[1])])
pearson_idx = np.argsort(pearson_scores)[::-1][:top_k]
X_pearson = X_scaled[:, pearson_idx]

# --- 3. Information Gain (Mutual Info) ---
mi_scores = mutual_info_classif(X_scaled, y, random_state=42)
mi_idx = np.argsort(mi_scores)[::-1][:top_k]
X_mi = X_scaled[:, mi_idx]

# --- 4. MCCA (ACC+BVP+TEMP) ---
acc_scaled = scaler.fit_transform(features_df.filter(regex="^acc_").values)
bvp_scaled = scaler.fit_transform(features_df.filter(regex="^bvp_").values)
temp_scaled = scaler.fit_transform(features_df.filter(regex="^temp_").values)
mcca = MCCA(n_components=15)
views = [acc_scaled, bvp_scaled, temp_scaled]
mcca_fused = mcca.fit_transform(views)
X_mcca = np.concatenate(mcca_fused, axis=1)

# --- 5. Random Forest Feature Importance ---
rf = RandomForestClassifier(n_estimators=200, random_state=42)
rf.fit(X_scaled, y)
rf_importances = rf.feature_importances_
rf_idx = np.argsort(rf_importances)[::-1][:top_k]
X_rf = X_scaled[:, rf_idx]

# --- Helper to train and evaluate ---
def train_evaluate(X_feat, method_name):
    X_train, X_test, y_train, y_test = split(X_feat, y)
    clf = RandomForestClassifier(n_estimators=200, random_state=42)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"\n=== {method_name} ===")
    print(f"Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred))
    return acc

# --- Evaluate all methods ---
acc_anova = train_evaluate(X_anova, "ANOVA F-test")
acc_pearson = train_evaluate(X_pearson, "Pearson Correlation")
acc_mi = train_evaluate(X_mi, "Information Gain")
acc_mcca = train_evaluate(X_mcca, "MCCA")
acc_rf = train_evaluate(X_rf, "Random Forest Feature Importance")

# --- Plot comparison ---
methods = ["ANOVA", "Pearson", "Info Gain", "MCCA", "RF Importance"]
accuracies = [acc_anova, acc_pearson, acc_mi, acc_mcca, acc_rf]

plt.figure(figsize=(8,5))
plt.bar(methods, accuracies, color=['blue','green','orange','red','purple'])
plt.ylabel("Accuracy")
plt.title("Comparison of 5 Feature Selection / Fusion Methods")
plt.ylim(0,1)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import f_classif, mutual_info_classif, chi2
from scipy.stats import pearsonr
from mvlearn.embed import MCCA

# --- Load Data ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")
features_df["label"] = features_df["label"] - 1
y = features_df["label"].values
X = features_df.drop(columns=["label"])
feature_names = X.columns

# --- Standard Scaling for methods that need it ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# --- Train/test split helper ---
def split(X_feat, y):
    return train_test_split(X_feat, y, test_size=0.2, stratify=y, random_state=42)

# -------------------------------
# 1. ANOVA F-test
# -------------------------------
f_scores, _ = f_classif(X_scaled, y)
top_k = 50
anova_idx = np.argsort(f_scores)[::-1][:top_k]
X_anova = X_scaled[:, anova_idx]

# -------------------------------
# 2. Pearson correlation
# -------------------------------
pearson_scores = np.array([abs(pearsonr(X.iloc[:,i], y)[0]) for i in range(X.shape[1])])
pearson_idx = np.argsort(pearson_scores)[::-1][:top_k]
X_pearson = X_scaled[:, pearson_idx]

# -------------------------------
# 3. Information Gain (Mutual Info)
# -------------------------------
mi_scores = mutual_info_classif(X_scaled, y, random_state=42)
mi_idx = np.argsort(mi_scores)[::-1][:top_k]
X_mi = X_scaled[:, mi_idx]

# -------------------------------
# 4. MCCA (ACC + BVP + TEMP)
# -------------------------------
acc_scaled = scaler.fit_transform(features_df.filter(regex="^acc_").values)
bvp_scaled = scaler.fit_transform(features_df.filter(regex="^bvp_").values)
temp_scaled = scaler.fit_transform(features_df.filter(regex="^temp_").values)
mcca = MCCA(n_components=15)
views = [acc_scaled, bvp_scaled, temp_scaled]
mcca_fused = mcca.fit_transform(views)
X_mcca = np.concatenate(mcca_fused, axis=1)

# -------------------------------
# 5. Chi-Square
# -------------------------------
# MinMax scale to [0,1] because chi2 requires non-negative
minmax = MinMaxScaler()
X_minmax = minmax.fit_transform(X)
chi2_scores, _ = chi2(X_minmax, y)
chi2_idx = np.argsort(chi2_scores)[::-1][:top_k]
X_chi2 = X_scaled[:, chi2_idx]

# -------------------------------
# Train & evaluate helper
# -------------------------------
def train_evaluate(X_feat, method_name):
    X_train, X_test, y_train, y_test = split(X_feat, y)
    clf = RandomForestClassifier(n_estimators=200, random_state=42)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"\n=== {method_name} ===")
    print(f"Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred))
    return acc

# --- Evaluate all methods ---
acc_anova = train_evaluate(X_anova, "ANOVA F-test")
acc_pearson = train_evaluate(X_pearson, "Pearson Correlation")
acc_mi = train_evaluate(X_mi, "Information Gain")
acc_mcca = train_evaluate(X_mcca, "MCCA")
acc_chi2 = train_evaluate(X_chi2, "Chi-Square")

# --- Plot comparison ---
methods = ["ANOVA", "Pearson", "Info Gain", "MCCA", "Chi-Square"]
accuracies = [acc_anova, acc_pearson, acc_mi, acc_mcca, acc_chi2]

plt.figure(figsize=(8,5))
plt.bar(methods, accuracies, color=['blue','green','orange','red','purple'])
plt.ylabel("Accuracy")
plt.title("Comparison of 5 Feature Selection / Fusion Methods")
plt.ylim(0,1)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import mutual_info_classif

# --- Load Data ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")
features_df["label"] = features_df["label"] - 1
y = features_df["label"].values
X = features_df.drop(columns=["label"])
feature_names = X.columns

# --- Standardize features ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# --- Compute Information Gain (Mutual Information) ---
mi_scores = mutual_info_classif(X_scaled, y, random_state=42)

# --- Select top-k features ---
top_k = 20
top_idx = np.argsort(mi_scores)[::-1][:top_k]
top_features = feature_names[top_idx]
top_scores = mi_scores[top_idx]

# --- Plot ---
plt.figure(figsize=(12,6))
plt.barh(top_features[::-1], top_scores[::-1], color='orange')
plt.xlabel("Mutual Information Score")
plt.title(f"Top-{top_k} Features Selected by Information Gain")
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import f_classif

# --- Load Data ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")
features_df["label"] = features_df["label"] - 1
y = features_df["label"].values
X = features_df.drop(columns=["label"])
feature_names = X.columns

# --- Standardize features ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# --- Compute ANOVA F-test ---
f_scores, _ = f_classif(X_scaled, y)

# --- Select top-k features ---
top_k = 20
top_idx = np.argsort(f_scores)[::-1][:top_k]
top_features = feature_names[top_idx]
top_scores = f_scores[top_idx]

# --- Plot ---
plt.figure(figsize=(12,6))
plt.barh(top_features[::-1], top_scores[::-1], color='skyblue')
plt.xlabel("F-score")
plt.title(f"Top-{top_k} Features Selected by ANOVA F-test")
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.feature_selection import chi2

# --- Load Data ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")
features_df["label"] = features_df["label"] - 1
y = features_df["label"].values
X = features_df.drop(columns=["label"])
feature_names = X.columns

# --- Scale features to [0,1] for chi-square ---
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# --- Compute Chi-Square scores ---
chi2_scores, _ = chi2(X_scaled, y)

# --- Select top-k features ---
top_k = 20
top_idx = np.argsort(chi2_scores)[::-1][:top_k]
top_features = feature_names[top_idx]
top_scores = chi2_scores[top_idx]

# --- Plot ---
plt.figure(figsize=(12,6))
plt.barh(top_features[::-1], top_scores[::-1], color='purple')
plt.xlabel("Chi-Square Score")
plt.title(f"Top-{top_k} Features Selected by Chi-Square Test")
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.feature_selection import f_classif, mutual_info_classif, chi2

# --- Load Data ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")
features_df["label"] = features_df["label"] - 1
y = features_df["label"].values
X = features_df.drop(columns=["label"])
feature_names = X.columns

# --- Standard Scale for ANOVA & Info Gain ---
scaler_std = StandardScaler()
X_scaled = scaler_std.fit_transform(X)

# --- MinMax Scale for Chi-Square ---
scaler_mm = MinMaxScaler()
X_minmax = scaler_mm.fit_transform(X)

top_k = 20

# --- ANOVA F-test ---
f_scores, _ = f_classif(X_scaled, y)
anova_idx = np.argsort(f_scores)[::-1][:top_k]
anova_features = feature_names[anova_idx]
anova_scores = f_scores[anova_idx]

# --- Information Gain ---
mi_scores = mutual_info_classif(X_scaled, y, random_state=42)
mi_idx = np.argsort(mi_scores)[::-1][:top_k]
mi_features = feature_names[mi_idx]
mi_scores_top = mi_scores[mi_idx]

# --- Chi-Square ---
chi2_scores, _ = chi2(X_minmax, y)
chi2_idx = np.argsort(chi2_scores)[::-1][:top_k]
chi2_features = feature_names[chi2_idx]
chi2_scores_top = chi2_scores[chi2_idx]

# --- Plot side-by-side horizontal bars ---
fig, axes = plt.subplots(1, 3, figsize=(18, 8))

axes[0].barh(anova_features[::-1], anova_scores[::-1], color='skyblue')
axes[0].set_title("ANOVA F-test")
axes[0].set_xlabel("F-score")

axes[1].barh(mi_features[::-1], mi_scores_top[::-1], color='orange')
axes[1].set_title("Information Gain")
axes[1].set_xlabel("Mutual Info Score")

axes[2].barh(chi2_features[::-1], chi2_scores_top[::-1], color='purple')
axes[2].set_title("Chi-Square")
axes[2].set_xlabel("Chi-Square Score")

plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import f_classif, mutual_info_classif, chi2
from scipy.stats import pearsonr
from mvlearn.embed import MCCA

# --- Load data ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")
features_df["label"] = features_df["label"] - 1
y = features_df["label"].values
X = features_df.drop(columns=["label"])
feature_names = X.columns

# --- Standard scaling ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# --- Train/test split helper ---
def split(X_feat):
    return train_test_split(X_feat, y, test_size=0.2, stratify=y, random_state=42)

# -------------------------------
# 1. ANOVA F-test
# -------------------------------
f_scores, _ = f_classif(X_scaled, y)
top_k = 50
anova_idx = np.argsort(f_scores)[::-1][:top_k]
X_anova = X_scaled[:, anova_idx]

# -------------------------------
# 2. Pearson correlation
# -------------------------------
pearson_scores = np.array([abs(pearsonr(X.iloc[:,i], y)[0]) for i in range(X.shape[1])])
pearson_idx = np.argsort(pearson_scores)[::-1][:top_k]
X_pearson = X_scaled[:, pearson_idx]

# -------------------------------
# 3. Information Gain (Mutual Info)
# -------------------------------
mi_scores = mutual_info_classif(X_scaled, y, random_state=42)
mi_idx = np.argsort(mi_scores)[::-1][:top_k]
X_mi = X_scaled[:, mi_idx]

# -------------------------------
# 4. Chi-Square
# -------------------------------
X_minmax = MinMaxScaler().fit_transform(X)  # chi2 requires non-negative
chi2_scores, _ = chi2(X_minmax, y)
chi2_idx = np.argsort(chi2_scores)[::-1][:top_k]
X_chi2 = X_scaled[:, chi2_idx]

# -------------------------------
# 5. Label-aware MCCA (MCCA + F-test)
# -------------------------------
# Separate modalities
acc_scaled = scaler.fit_transform(features_df.filter(regex="^acc_").values)
bvp_scaled = scaler.fit_transform(features_df.filter(regex="^bvp_").values)
temp_scaled = scaler.fit_transform(features_df.filter(regex="^temp_").values)

# Apply MCCA
mcca = MCCA(n_components=15)
views = [acc_scaled, bvp_scaled, temp_scaled]
mcca_fused = mcca.fit_transform(views)
X_mcca = np.concatenate(mcca_fused, axis=1)

# Apply ANOVA F-test on fused components to make it label-aware
f_mcca_scores, _ = f_classif(X_mcca, y)
top_mcca_idx = np.argsort(f_mcca_scores)[::-1][:10]  # select top 10 components
X_mcca_label = X_mcca[:, top_mcca_idx]

# -------------------------------
# Helper function to train & evaluate
# -------------------------------
def train_evaluate(X_feat, method_name):
    X_train, X_test, y_train, y_test = split(X_feat)
    clf = RandomForestClassifier(n_estimators=200, random_state=42)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"\n=== {method_name} ===")
    print(f"Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred))
    return acc

# -------------------------------
# Evaluate all methods
# -------------------------------
acc_anova = train_evaluate(X_anova, "ANOVA F-test")
acc_pearson = train_evaluate(X_pearson, "Pearson Correlation")
acc_mi = train_evaluate(X_mi, "Information Gain")
acc_chi2 = train_evaluate(X_chi2, "Chi-Square")
acc_mcca_label = train_evaluate(X_mcca_label, "Label-aware MCCA")

# -------------------------------
# Plot accuracy comparison
# -------------------------------
methods = ["ANOVA", "Pearson", "Info Gain", "Chi-Square", "Label-aware MCCA"]
accuracies = [acc_anova, acc_pearson, acc_mi, acc_chi2, acc_mcca_label]

plt.figure(figsize=(8,5))
plt.bar(methods, accuracies, color=['blue','green','orange','purple','red'])
plt.ylabel("Accuracy")
plt.title("Comparison of 5 Feature Selection / Fusion Methods")
plt.ylim(0,1)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import mutual_info_classif
from sklearn.metrics import classification_report, accuracy_score
from mvlearn.embed import MCCA

# --- Load Data ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")
features_df["label"] = features_df["label"] - 1
y = features_df["label"].values

# --- Separate modalities ---
acc_scaled = StandardScaler().fit_transform(features_df.filter(regex="^acc_").values)
bvp_scaled = StandardScaler().fit_transform(features_df.filter(regex="^bvp_").values)
temp_scaled = StandardScaler().fit_transform(features_df.filter(regex="^temp_").values)

# --- Step 1: Apply MCCA (unsupervised fusion) ---
mcca = MCCA(n_components=15)
views = [acc_scaled, bvp_scaled, temp_scaled]
mcca_fused = mcca.fit_transform(views)
X_mcca = np.concatenate(mcca_fused, axis=1)
print("Shape after MCCA fusion:", X_mcca.shape)

# --- Step 2: Apply Information Gain (Mutual Information) on fused components ---
mi_scores = mutual_info_classif(X_mcca, y, random_state=42)
top_k = 10
top_idx = np.argsort(mi_scores)[::-1][:top_k]
X_mcca_ig = X_mcca[:, top_idx]

print(f"Selected top-{top_k} label-aware MCCA components using Information Gain.")

# --- Step 3: Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(
    X_mcca_ig, y, test_size=0.2, stratify=y, random_state=42
)

# --- Step 4: Train Random Forest Classifier ---
clf = RandomForestClassifier(n_estimators=200, random_state=42)
clf.fit(X_train, y_train)

# --- Step 5: Evaluate ---
y_pred = clf.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print("\n=== Label-aware MCCA (with Info Gain) ===")
print(f"Accuracy: {acc:.4f}")
print(classification_report(y_test, y_pred))

# --- Step 6: Plot top components by Information Gain ---
top_scores = mi_scores[top_idx]
component_names = [f"MCCA_comp_{i+1}" for i in top_idx]

plt.figure(figsize=(8,5))
plt.barh(component_names[::-1], top_scores[::-1], color='orange')
plt.xlabel("Mutual Information Score")
plt.title(f"Top-{top_k} Label-aware MCCA Components (Info Gain)")
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import mutual_info_classif
from sklearn.metrics import classification_report, accuracy_score
from sklearn.svm import SVC

# --- Load Data ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")
features_df["label"] = features_df["label"] - 1
y = features_df["label"].values

# --- Combine all modalities (already feature extracted) ---
X = features_df.drop(columns=["label"]).values
X = StandardScaler().fit_transform(X)

# --- Step 1: Apply Information Gain (Mutual Information) ---
mi_scores = mutual_info_classif(X, y, random_state=42)
top_k = 20
top_idx = np.argsort(mi_scores)[::-1][:top_k]
X_selected = X[:, top_idx]

print(f"Selected top-{top_k} features using Information Gain.")

# --- Step 2: Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(
    X_selected, y, test_size=0.2, stratify=y, random_state=42
)

# --- Step 3: Train SVM Classifier ---
clf = SVC(kernel='rbf', C=10, gamma='scale', random_state=42)
clf.fit(X_train, y_train)

# --- Step 4: Evaluate ---
y_pred = clf.predict(X_test)
acc = accuracy_score(y_test, y_pred)
print("\n=== Info Gain + SVM ===")
print(f"Accuracy: {acc:.4f}")
print(classification_report(y_test, y_pred))

# --- Step 5: Plot top features by Information Gain ---
top_scores = mi_scores[top_idx]
feature_names = features_df.drop(columns=["label"]).columns[top_idx]

plt.figure(figsize=(8,5))
plt.barh(feature_names[::-1], top_scores[::-1], color='orange')
plt.xlabel("Mutual Information Score")
plt.title(f"Top-{top_k} Features (Info Gain)")
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import mutual_info_classif
from sklearn.metrics import classification_report, accuracy_score
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier

# --- Load Data ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")
features_df["label"] = features_df["label"] - 1
y = features_df["label"].values

# --- Feature matrix ---
X = features_df.drop(columns=["label"]).values
X = StandardScaler().fit_transform(X)

# --- Step 1: Information Gain (Mutual Information) ---
mi_scores = mutual_info_classif(X, y, random_state=42)
top_k = 20
top_idx = np.argsort(mi_scores)[::-1][:top_k]
X_selected = X[:, top_idx]
feature_names = features_df.drop(columns=["label"]).columns[top_idx]

print(f"Selected top-{top_k} features using Information Gain.")

# --- Step 2: Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(
    X_selected, y, test_size=0.2, stratify=y, random_state=42
)

# --- Step 3a: SVM ---
svm_clf = SVC(kernel='rbf', C=10, gamma='scale', random_state=42)
svm_clf.fit(X_train, y_train)
y_pred_svm = svm_clf.predict(X_test)

# --- Step 3b: Decision Tree ---
dt_clf = DecisionTreeClassifier(max_depth=10, random_state=42)
dt_clf.fit(X_train, y_train)
y_pred_dt = dt_clf.predict(X_test)

# --- Step 3c: Neural Network (MLP) ---
mlp_clf = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu',
                        solver='adam', max_iter=500, random_state=42)
mlp_clf.fit(X_train, y_train)
y_pred_mlp = mlp_clf.predict(X_test)

# --- Step 4: Evaluation ---
print("\n=== Info Gain + SVM ===")
print(f"Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}")
print(classification_report(y_test, y_pred_svm))

print("\n=== Info Gain + Decision Tree ===")
print(f"Accuracy: {accuracy_score(y_test, y_pred_dt):.4f}")
print(classification_report(y_test, y_pred_dt))

print("\n=== Info Gain + Neural Network (MLP) ===")
print(f"Accuracy: {accuracy_score(y_test, y_pred_mlp):.4f}")
print(classification_report(y_test, y_pred_mlp))

# --- Step 5: Plot top features by Information Gain ---
top_scores = mi_scores[top_idx]

plt.figure(figsize=(8,5))
plt.barh(feature_names[::-1], top_scores[::-1], color='orange')
plt.xlabel("Mutual Information Score")
plt.title(f"Top-{top_k} Features (Info Gain)")
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import mutual_info_classif
from sklearn.metrics import classification_report, accuracy_score
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier

# --- Load Data ---
features_df = pd.read_csv("/content/wesad_features_stft_30s_1.csv")
features_df["label"] = features_df["label"] - 1
y = features_df["label"].values

# --- Feature Matrix ---
X = features_df.drop(columns=["label"]).values
X = StandardScaler().fit_transform(X)

# --- Step 1: Information Gain (Mutual Information) ---
mi_scores = mutual_info_classif(X, y, random_state=42)
top_k = 50
top_idx = np.argsort(mi_scores)[::-1][:top_k]
X_selected = X[:, top_idx]
feature_names = features_df.drop(columns=["label"]).columns[top_idx]

print(f"Selected top-{top_k} features using Information Gain.")

# --- Step 2: Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(
    X_selected, y, test_size=0.2, stratify=y, random_state=42
)

# --- Step 3a: SVM ---
svm_clf = SVC(kernel='rbf', C=10, gamma='scale', random_state=42)
svm_clf.fit(X_train, y_train)
y_pred_svm = svm_clf.predict(X_test)

# --- Step 3b: Decision Tree ---
dt_clf = DecisionTreeClassifier(max_depth=15, random_state=42)
dt_clf.fit(X_train, y_train)
y_pred_dt = dt_clf.predict(X_test)

# --- Step 3c: Neural Network (MLP) ---
mlp_clf = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu',
                        solver='adam', max_iter=500, random_state=42)
mlp_clf.fit(X_train, y_train)
y_pred_mlp = mlp_clf.predict(X_test)

# --- Step 4: Evaluation ---
def evaluate_model(name, y_true, y_pred):
    acc = accuracy_score(y_true, y_pred)
    print(f"\n=== Info Gain (Top-{top_k}) + {name} ===")
    print(f"Accuracy: {acc:.4f}")
    print(classification_report(y_true, y_pred))

evaluate_model("SVM", y_test, y_pred_svm)
evaluate_model("Decision Tree", y_test, y_pred_dt)
evaluate_model("Neural Network (MLP)", y_test, y_pred_mlp)

# --- Step 5: Plot top-50 features by Information Gain ---
top_scores = mi_scores[top_idx]

plt.figure(figsize=(12,6))
plt.barh(feature_names[::-1], top_scores[::-1], color='orange')
plt.xlabel("Mutual Information Score")
plt.title(f"Top-{top_k} Features (Information Gain)")
plt.grid(axis='x', linestyle='--', alpha=0.7)
plt.show()

import matplotlib.pyplot as plt

# Classifier names
classifiers = ["Random Forest", "SVM", "Decision Tree", "MLP"]

# Accuracies (IG Top-50 results)
accuracies = [99.66, 96.01, 96.36, 98.63]

# Subtle pastel colors
colors = ['#a6cee3', '#b2df8a', '#fb9a99', '#cab2d6']

plt.figure(figsize=(8,6))
bars = plt.bar(classifiers, accuracies, color=colors, alpha=0.8)

# Add values slightly above bars
for bar, acc in zip(bars, accuracies):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3,
             f"{acc:.2f}%", ha='center', va='bottom', fontsize=11)

plt.ylim(90, 101)
plt.ylabel("Accuracy (%)", fontsize=12)
plt.title("Classifier Performance with Information Gain (Top-50 Features)", fontsize=14)
plt.grid(axis="y", linestyle="--", alpha=0.3)
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import mutual_info_classif
from sklearn.metrics import classification_report, accuracy_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, Dropout
from tensorflow.keras.utils import to_categorical

# --- Load Data ---
features_df = pd.read_csv("/content/wesad_features_stft_30s_1.csv")
features_df["label"] = features_df["label"] - 1
y = features_df["label"].values

# --- Feature Matrix ---
X = features_df.drop(columns=["label"]).values
X = StandardScaler().fit_transform(X)

# --- Step 1: Information Gain (Mutual Information) ---
mi_scores = mutual_info_classif(X, y, random_state=42)
top_k = 50   # more features for deep models
top_idx = np.argsort(mi_scores)[::-1][:top_k]
X_selected = X[:, top_idx]

print(f"Selected top-{top_k} features using Information Gain.")

# --- Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(
    X_selected, y, test_size=0.2, stratify=y, random_state=42
)

# --- Reshape for CNN/LSTM (samples, timesteps, features_per_step) ---
# Here: treat each feature as "a timestep with 1 feature"
X_train_seq = np.expand_dims(X_train, axis=2)
X_test_seq = np.expand_dims(X_test, axis=2)

# One-hot encode labels
num_classes = len(np.unique(y))
y_train_cat = to_categorical(y_train, num_classes=num_classes)
y_test_cat = to_categorical(y_test, num_classes=num_classes)

# --- CNN Model ---
cnn_model = Sequential([
    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train_seq.shape[1], 1)),
    MaxPooling1D(pool_size=2),
    Flatten(),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
cnn_model.summary()

cnn_model.fit(X_train_seq, y_train_cat, epochs=15, batch_size=32,
              validation_split=0.2, verbose=1)

cnn_acc = cnn_model.evaluate(X_test_seq, y_test_cat, verbose=0)[1]
print(f"\n=== Info Gain + CNN ===\nAccuracy: {cnn_acc:.4f}")

# --- LSTM Model ---
lstm_model = Sequential([
    LSTM(64, input_shape=(X_train_seq.shape[1], 1), return_sequences=False),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
lstm_model.summary()

lstm_model.fit(X_train_seq, y_train_cat, epochs=15, batch_size=32,
               validation_split=0.2, verbose=1)

lstm_acc = lstm_model.evaluate(X_test_seq, y_test_cat, verbose=0)[1]
print(f"\n=== Info Gain + LSTM ===\nAccuracy: {lstm_acc:.4f}")

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import f_classif, chi2, mutual_info_classif
from scipy.stats import pearsonr
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, Dropout
from tensorflow.keras.utils import to_categorical

# --- Load Data ---
features_df = pd.read_csv("/content/wesad_features_stft_30s.csv")
features_df["label"] = features_df["label"] - 1
y = features_df["label"].values

# --- Feature Matrix ---
X = features_df.drop(columns=["label"]).values
X = StandardScaler().fit_transform(X)

# ---------------------------
# Feature Selection Functions
# ---------------------------
def select_features(X, y, method="mi", k=50):
    if method == "mi":  # Information Gain (Mutual Information)
        scores = mutual_info_classif(X, y, random_state=42)
        top_idx = np.argsort(scores)[::-1][:k]
        return X[:, top_idx]

    elif method == "f_test":  # ANOVA F-test
        scores, _ = f_classif(X, y)
        top_idx = np.argsort(scores)[::-1][:k]
        return X[:, top_idx]

    elif method == "chi2":  # Chi-square (needs non-negative features)
        X_pos = MinMaxScaler().fit_transform(X)
        scores, _ = chi2(X_pos, y)
        top_idx = np.argsort(scores)[::-1][:k]
        return X[:, top_idx]

    elif method == "pearson":  # Pearson correlation
        scores = [abs(pearsonr(X[:, j], y)[0]) for j in range(X.shape[1])]
        top_idx = np.argsort(scores)[::-1][:k]
        return X[:, top_idx]



    else:
        raise ValueError("Unknown method")

# ---------------------------
# Train + Evaluate Deep Models
# ---------------------------
def run_deep_models(X, y, method="mi", k=50, epochs=10, batch_size=32):
    X_sel = select_features(X, y, method=method, k=k)

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(
        X_sel, y, test_size=0.2, stratify=y, random_state=42
    )

    # Reshape for CNN/LSTM (samples, timesteps, features_per_step)
    X_train_seq = np.expand_dims(X_train, axis=2)
    X_test_seq = np.expand_dims(X_test, axis=2)

    # One-hot encode labels
    num_classes = len(np.unique(y))
    y_train_cat = to_categorical(y_train, num_classes=num_classes)
    y_test_cat = to_categorical(y_test, num_classes=num_classes)

    # --- CNN ---
    cnn_model = Sequential([
        Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train_seq.shape[1], 1)),
        MaxPooling1D(pool_size=2),
        Flatten(),
        Dense(64, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])
    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    cnn_model.fit(X_train_seq, y_train_cat, epochs=epochs, batch_size=batch_size,
                  validation_split=0.2, verbose=0)
    cnn_acc = cnn_model.evaluate(X_test_seq, y_test_cat, verbose=0)[1]

    # --- LSTM ---
    lstm_model = Sequential([
        LSTM(64, input_shape=(X_train_seq.shape[1], 1), return_sequences=False),
        Dense(64, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])
    lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    lstm_model.fit(X_train_seq, y_train_cat, epochs=epochs, batch_size=batch_size,
                   validation_split=0.2, verbose=0)
    lstm_acc = lstm_model.evaluate(X_test_seq, y_test_cat, verbose=0)[1]

    return cnn_acc, lstm_acc

# ---------------------------
# Run Experiments
# ---------------------------
methods = ["mi", "f_test", "chi2", "pearson"]
k_values = [10, 20, 50]

results = []

for method in methods:
    for k in k_values:
        cnn_acc, lstm_acc = run_deep_models(X, y, method=method, k=k)
        results.append([method.upper(), k, cnn_acc, lstm_acc])

# ---------------------------
# Save Results
# ---------------------------
df_results = pd.DataFrame(results, columns=["Method", "Top-K", "CNN Accuracy", "LSTM Accuracy"])
print(df_results)

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import f_classif, chi2, mutual_info_classif
from scipy.stats import pearsonr
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# --- Load Data ---
features_df = pd.read_csv("/content/wesad_features_stft_30s_1.csv")
features_df["label"] = features_df["label"] - 1
y = features_df["label"].values

# --- Feature Matrix ---
X = features_df.drop(columns=["label"]).values
X = StandardScaler().fit_transform(X)

# ---------------------------
# Feature Selection Functions
# ---------------------------
def select_features(X, y, method="mi", k=50):
    if method == "mi":  # Information Gain
        scores = mutual_info_classif(X, y, random_state=42)
        top_idx = np.argsort(scores)[::-1][:k]
        return X[:, top_idx]

    elif method == "f_test":  # ANOVA F-test
        scores, _ = f_classif(X, y)
        top_idx = np.argsort(scores)[::-1][:k]
        return X[:, top_idx]

    elif method == "chi2":  # Chi-square (needs non-negative values)
        X_pos = MinMaxScaler().fit_transform(X)
        scores, _ = chi2(X_pos, y)
        top_idx = np.argsort(scores)[::-1][:k]
        return X[:, top_idx]

    elif method == "pearson":  # Pearson correlation
        scores = [abs(pearsonr(X[:, j], y)[0]) for j in range(X.shape[1])]
        top_idx = np.argsort(scores)[::-1][:k]
        return X[:, top_idx]


    else:
        raise ValueError("Unknown method")

# ---------------------------
# Evaluation Function
# ---------------------------
def evaluate_rf(X, y, method="mi", k=50):
    X_sel = select_features(X, y, method=method, k=k)

    X_train, X_test, y_train, y_test = train_test_split(
        X_sel, y, test_size=0.2, stratify=y, random_state=42
    )

    clf = RandomForestClassifier(n_estimators=200, random_state=42)
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)

    return [
        accuracy_score(y_test, y_pred) * 100,
        precision_score(y_test, y_pred, average="weighted") * 100,
        recall_score(y_test, y_pred, average="weighted") * 100,
        f1_score(y_test, y_pred, average="weighted") * 100,
    ]

# ---------------------------
# Run Experiments
# ---------------------------
methods = ["mi", "f_test", "chi2", "pearson"]
k_values = [10, 20, 50]

results = []
for method in methods:
    for k in k_values:
        acc, prec, rec, f1 = evaluate_rf(X, y, method=method, k=k)
        results.append([method.upper(), k, acc, prec, rec, f1])

# ---------------------------
# Save Results
# ---------------------------
df_results = pd.DataFrame(results, columns=["Method", "Top-K", "Accuracy", "Precision", "Recall", "F1-score"])
print(df_results)

# Export LaTeX table
df_results.to_latex("wesad_rf_results.tex", index=False, float_format="%.2f")

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import mutual_info_classif
from sklearn.ensemble import RandomForestClassifier

# --- Load Data ---
features_df = pd.read_csv("/content/wesad_features_stft_30s_1.csv")
features_df["label"] = features_df["label"] - 1
y = features_df["label"].values

# --- Feature Matrix ---
X = features_df.drop(columns=["label"]).values
feature_names = features_df.drop(columns=["label"]).columns
X = StandardScaler().fit_transform(X)

# --- Information Gain (Top-50 Features) ---
mi_scores = mutual_info_classif(X, y, random_state=42)
top_idx = np.argsort(mi_scores)[::-1][:50]
X_selected = X[:, top_idx]
selected_features = feature_names[top_idx]

# --- Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(
    X_selected, y, test_size=0.2, stratify=y, random_state=42
)

# --- Random Forest Classifier ---
clf = RandomForestClassifier(n_estimators=200, random_state=42)
clf.fit(X_train, y_train)

# --- Feature Importances ---
importances = clf.feature_importances_
indices = np.argsort(importances)[::-1]

# --- Plot Top-50 Feature Importances ---
plt.figure(figsize=(12, 8))
plt.bar(range(50), importances[indices], align="center")
plt.xticks(range(50), [selected_features[i] for i in indices], rotation=90, fontsize=8)
plt.title("Top-50 Features (Information Gain) - Importance by Random Forest")
plt.ylabel("Feature Importance")
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load your processed STFT dataset
df = pd.read_csv("/content/wesad_features_stft_30s_1.csv")

# Map labels (optional, for clarity)
label_map = {1: "Baseline", 2: "Stress", 3: "Amusement"}
df["label_name"] = df["label"].map(label_map)

# Group features by modality
acc_features = [c for c in df.columns if c.startswith("acc")]
bvp_features = [c for c in df.columns if c.startswith("bvp")]
eda_features = [c for c in df.columns if c.startswith("eda")]
temp_features = [c for c in df.columns if c.startswith("temp")]

print("ACC features:", len(acc_features))
print("BVP features:", len(bvp_features))
print("EDA features:", len(eda_features))
print("TEMP features:", len(temp_features))

# -------------------------
# 1. Statistical summary per modality
# -------------------------
summary = {}
for name, features in zip(["ACC", "BVP", "EDA", "TEMP"],
                          [acc_features, bvp_features, eda_features, temp_features]):
    summary[name] = df[features].describe().T[["mean", "std", "min", "max"]]

# Example: print BVP summary
print("\nBVP Feature Summary:\n", summary["BVP"].head())

# -------------------------
# 2. Distribution plots
# -------------------------
def plot_feature_distribution(features, modality):
    plt.figure(figsize=(12,6))
    for f in features[:3]:  # plot first 3 features for clarity
        sns.kdeplot(data=df, x=f, hue="label_name", common_norm=False, fill=True, alpha=0.4)
    plt.title(f"{modality} Feature Distributions Across Classes")
    plt.show()

plot_feature_distribution(bvp_features, "BVP")
plot_feature_distribution(eda_features, "EDA")
plot_feature_distribution(acc_features, "ACC")
plot_feature_distribution(temp_features, "TEMP")

# -------------------------
# 3. Per-class averages (for interpretation)
# -------------------------
class_means = df.groupby("label_name").mean(numeric_only=True).T
print("\nTop 10 features differing across classes:\n",
      class_means.loc[bvp_features].head(10))

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load dataset
df = pd.read_csv("/content/wesad_features_stft_30s_1.csv")

# Map labels for clarity
label_map = {1: "Baseline", 2: "Stress", 3: "Amusement"}
df["label_name"] = df["label"].map(label_map)

# Group features by modality
acc_features = [c for c in df.columns if c.startswith("acc")]
bvp_features = [c for c in df.columns if c.startswith("bvp")]
eda_features = [c for c in df.columns if c.startswith("eda")]
temp_features = [c for c in df.columns if c.startswith("temp")]

# Subplots for modalities
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
axes = axes.flatten()

modalities = {
    "BVP": bvp_features,
    "EDA": eda_features,
    "ACC": acc_features,
    "TEMP": temp_features
}

# Loop over modalities and plot first 3 features for each
for ax, (modality, features) in zip(axes, modalities.items()):
    for f in features[:3]:  # just first 3 features per modality
        sns.kdeplot(data=df, x=f, hue="label_name", common_norm=False,
                    fill=True, alpha=0.4, ax=ax)
    ax.set_title(f"{modality} Features Across Classes")

plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.feature_selection import f_classif

# Load dataset
df = pd.read_csv("/content/wesad_features_stft_30s_1.csv")

# Map labels
label_map = {1: "Baseline", 2: "Stress", 3: "Amusement"}
df["label_name"] = df["label"].map(label_map)

# Group features by modality
acc_features = [c for c in df.columns if c.startswith("acc")]
bvp_features = [c for c in df.columns if c.startswith("bvp")]
eda_features = [c for c in df.columns if c.startswith("eda")]
temp_features = [c for c in df.columns if c.startswith("temp")]

# Separate X and y
X = df.drop(columns=["label", "label_name"])
y = df["label"]

# F-test feature ranking
f_scores, _ = f_classif(X, y)
f_scores = np.nan_to_num(f_scores, nan=0.0)  # handle any NaN scores

# Select top-3 features per modality
modalities = {
    "BVP": bvp_features,
    "EDA": eda_features,
    "ACC": acc_features,
    "TEMP": temp_features
}
top_features = {}
for modality, features in modalities.items():
    feat_scores = [(f, f_scores[X.columns.get_loc(f)]) for f in features]
    top_features[modality] = sorted(feat_scores, key=lambda x: x[1], reverse=True)[:3]

print("Top-3 discriminative features per modality:\n", top_features)

# Prepare subplots
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
axes = axes.flatten()

# Plot KDEs
for ax, (modality, feats) in zip(axes, top_features.items()):
    for f, score in feats:
        if modality in ["EDA", "TEMP"]:   # log transform skewed modalities
            sns.kdeplot(
                data=df,
                x=np.log1p(df[f]),
                hue="label_name",
                common_norm=False,
                fill=True, alpha=0.4,
                ax=ax,
                label=f"{f} (log)"
            )
        else:
            sns.kdeplot(
                data=df,
                x=df[f],
                hue="label_name",
                common_norm=False,
                fill=True, alpha=0.4,
                ax=ax,
                label=f
            )
    ax.set_title(f"{modality} Top-3 Features Across Classes")

plt.tight_layout()
plt.show()